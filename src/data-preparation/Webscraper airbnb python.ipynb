{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f07201",
   "metadata": {},
   "source": [
    "# Python webscraper Inside Airbnb\n",
    "This webscraper is built to extract all the \"listing.csv.gz\" download links from Inside Airbnb at once. \n",
    "These various download links are stored in a csv that is the basis for downloading all the data in R Studio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f4210",
   "metadata": {},
   "source": [
    "### 1) Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51bdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5bab8",
   "metadata": {},
   "source": [
    "### 2) Prepare Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd0b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "inside_airbnb_url= \"http://insideairbnb.com/get-the-data.html\"\n",
    "driver.get(inside_airbnb_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b80bb6",
   "metadata": {},
   "source": [
    "### 3) set up the url to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea809c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_airbnb_url= \"http://insideairbnb.com/get-the-data.html\"\n",
    "driver.get(inside_airbnb_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae343865",
   "metadata": {},
   "source": [
    "### 4) Load the page source and open it with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = driver.page_source # Load the page source\n",
    "soup = BeautifulSoup(res, features=\"html.parser\") # Open the page source with BeautifulSoup\n",
    "cities_list=soup.find_all('tbody') # Create a list of all the cities (identified by 'tbody')\n",
    "identifier_list=soup.find_all('h3') # Create a list that provides the identifier of the city (which is: the city, province/state, and country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712a090",
   "metadata": {},
   "source": [
    "### 5) The loop to get data from all the EU cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_data=[] # Creating a list to store the data in\n",
    "for city in range(len(cities_list)):\n",
    "    tmp_url = cities_list[city].find(\"a\").get('href') # Open the first \"a\" in each 'tbody' (since the listings.csv.gz file is here) and only extract the 'href' (which is the link of the csv.gz file)\n",
    "    identifier = identifier_list[city].text # Get the identifier that corresponds to this city (i.e. the city, state/province, country variable)\n",
    "    country = identifier.split(\",\",3)[-1] # Save the country, which is always the last part of the identifier that seperates city, state/province and country by comma's.\n",
    "    city = identifier.split(\",\",3)[0] # \n",
    "    \n",
    "    # Store the city, country and URL link in a temporary dictionary:\n",
    "    city_info = {\"Country\": country, \"City\": city ,\"Link\": tmp_url}\n",
    "    \n",
    "    # Append the temporary dictionary to the list of all cities:\n",
    "    city_data.append(city_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49468d8",
   "metadata": {},
   "source": [
    "### 6) Save the data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70962e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(city_data)).to_csv(\"Airbnb_listing_urls.csv\", index=False, sep=';') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
